{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3200eff8-f10f-4473-b027-82048f479efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d6352e-1033-4ce0-9a03-1805ccb4f319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from naive_bayes import *\n",
    "from bert1 import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2687703-f98d-41a3-b4e5-30829c721987",
   "metadata": {},
   "source": [
    "Firstly, we load train, validation and test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12bc8f9-cf4a-4175-9340-d5aeb1dfc9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_directory = \"stance\"\n",
    "\n",
    "dataset_train = [f\"{dataset_directory}/stance_hillary_train.csv\", \n",
    "                 f\"{dataset_directory}/stance_feminist_train.csv\", \n",
    "                 f\"{dataset_directory}/stance_climate_train.csv\", \n",
    "                 f\"{dataset_directory}/stance_atheism_train.csv\", \n",
    "                 f\"{dataset_directory}/stance_abortion_train.csv\"]\n",
    "\n",
    "train_hillary = pd.read_csv(f\"{dataset_directory}/stance_hillary_train.csv\")\n",
    "train_feminist = pd.read_csv(f\"{dataset_directory}/stance_feminist_train.csv\")\n",
    "train_climate = pd.read_csv(f\"{dataset_directory}/stance_climate_train.csv\")\n",
    "train_atheism = pd.read_csv(f\"{dataset_directory}/stance_atheism_train.csv\")\n",
    "train_abortion = pd.read_csv(f\"{dataset_directory}/stance_abortion_train.csv\")\n",
    "\n",
    "\n",
    "dataset_test = [f\"{dataset_directory}/stance_hillary_test.csv\", \n",
    "                 f\"{dataset_directory}/stance_feminist_test.csv\", \n",
    "                 f\"{dataset_directory}/stance_climate_test.csv\", \n",
    "                 f\"{dataset_directory}/stance_atheism_test.csv\", \n",
    "                 f\"{dataset_directory}/stance_abortion_test.csv\"]\n",
    "\n",
    "test_hillary = pd.read_csv(f\"{dataset_directory}/stance_hillary_test.csv\")\n",
    "test_feminist = pd.read_csv(f\"{dataset_directory}/stance_feminist_test.csv\")\n",
    "test_climate = pd.read_csv(f\"{dataset_directory}/stance_climate_test.csv\")\n",
    "test_atheism = pd.read_csv(f\"{dataset_directory}/stance_atheism_test.csv\")\n",
    "test_abortion = pd.read_csv(f\"{dataset_directory}/stance_abortion_test.csv\")\n",
    "\n",
    "df_train = [pd.read_csv(file) for file in dataset_train]\n",
    "df_train[0]['target'] = \"hillary\"\n",
    "df_train[1]['target'] = \"feminist\"\n",
    "df_train[2]['target'] = \"climate\"\n",
    "df_train[3]['target'] = \"atheism\"\n",
    "df_train[4]['target'] = \"abortion\"\n",
    "train = pd.concat(df_train, ignore_index=True)\n",
    "\n",
    "df_test = [pd.read_csv(file) for file in dataset_test]\n",
    "df_test[0]['target'] = \"hillary\"\n",
    "df_test[1]['target'] = \"feminist\"\n",
    "df_test[2]['target'] = \"climate\"\n",
    "df_test[3]['target'] = \"atheism\"\n",
    "df_test[4]['target'] = \"abortion\"\n",
    "test = pd.concat(df_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da98e5-72db-4ab7-956a-3d486d77a16f",
   "metadata": {},
   "source": [
    "# 0 Data Preprocess\n",
    "Our dataset comprises tweets, which, unlike other data forms such as news releases, often display unconventional expressions. This irregularity poses challenges in tokenization and feature extraction. To mitigate these issues, it's crucial to undertake data preprocessing that's specifically designed for the unique attributes of tweets. We have segmented this preprocessing into several steps:\n",
    "\n",
    "## 0.1 Eliminate \"@user\"\n",
    "It's important to note the frequent presence of \"@user\" in Twitter texts. These mentions often don't contribute meaningful information to the analysis. As such, we choose to disregard these specific terms in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b653d8-70cf-4718-8a2c-c92246df5dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['text'] = train['text'].str.replace('@user', '', regex=False)\n",
    "# validation['text'] = validation['text'].str.replace('@user', '', regex=False)\n",
    "test['text'] = test['text'].str.replace('@user', '', regex=False)\n",
    "train['text'][2618]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6523ac5-3cd2-4790-a0ce-2806b663dd6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['text'] = train['text'].str.replace('#SemST', '', regex=False)\n",
    "# validation['text'] = validation['text'].str.replace('#SemST', '', regex=False)\n",
    "test['text'] = test['text'].str.replace('#SemST', '', regex=False)\n",
    "\n",
    "train['text'] = train['text'].str.replace('#', '', regex=False)\n",
    "# validation['text'] = validation['text'].str.replace('#', '', regex=False)\n",
    "test['text'] = test['text'].str.replace('#', '', regex=False)\n",
    "train['text'][2618]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1f3c4-53b3-4674-a62f-ea75459d4283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lowercase_text(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "train['text'] = train['text'].apply(lowercase_text)\n",
    "# validation['text'] = validation['text'].apply(lowercase_text)\n",
    "test['text'] = test['text'].apply(lowercase_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f6bc5-d94b-48b4-a940-90ac5e1460d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_abbreviations(text):\n",
    "    abbreviations = {\n",
    "        \"u\": \"you\",\n",
    "        \"r\": \"are\",\n",
    "        \"b4\": \"before\",\n",
    "        \"b/w\": \"between\", \n",
    "        \"what's\": \"what is\",\n",
    "        \"l8r\": \"later\", \n",
    "        \"gr8\": \"great\",\n",
    "        \"thx\": \"thanks\", \n",
    "        \"tx\": \"thanks\", \n",
    "        \"she's\": \"she is\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"we're\": \"We are\",\n",
    "        \"that's\": \"That is\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"btw\": \"by the way\", \n",
    "        \"idk\": \"i don't know\", \n",
    "        \"imo\": \"in my opinion\", \n",
    "        \"isn't\": \"is not\",\n",
    "        \"here's\": \"Here is\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"you've\": \"you have\",\n",
    "        \"i'm\": \"I am\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"you'll\": \"you will\",\n",
    "        \"you'd\": \"You would\",\n",
    "        \"it's\": \"It is\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"they'd\": \"they would\",\n",
    "        \"i'll\": \"I will\",\n",
    "        \"gov't\": \"government\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"who'd\": \"who would\",\n",
    "        \"i've\": \"I have\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"who's\": \"who is\",\n",
    "        \"youve\": \"you have\",\n",
    "        \"he'll\": \"he will\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"it'll\": \"it will\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"can't\": \"Cannot\",\n",
    "        \"ain't\": \"am not\",\n",
    "        \"ur's\": \"yours\",\n",
    "        \"ca't\": \"cannot\",\n",
    "        \"here`s\": \"here is\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"he's\": \"he is\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"tnx\": \"thanks\", \n",
    "        \"ty\": \"thank you\", \n",
    "        \"asap\": \"as soon as possible\", \n",
    "        \"w/o\": \"without\"\n",
    "    }\n",
    "    return \" \".join([abbreviations.get(word, word) for word in text.split()])\n",
    "\n",
    "train['text'] = train['text'].apply(replace_abbreviations)\n",
    "# validation['text'] = validation['text'].apply(replace_abbreviations)\n",
    "test['text'] = test['text'].apply(replace_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46842678-9b03-4b4d-97b6-57fde2ab858a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "train['text'] = train['text'].apply(clean_text)\n",
    "# validation['text'] = validation['text'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c8ef1-8928-4d2b-9303-01faf6f69452",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea54b9-ad2b-42ba-8b6d-e03d3389b1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_basic_stats(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c33a7-5e12-429c-9a86-dd1e8e52eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayes()\n",
    "naive_bayes.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a279a-7f87-4e59-8286-6c5033f5ed40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aebc42-dede-411b-9844-c7a2dcdd3283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc536954-5f8b-4602-91b2-53da1bb8b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayes()\n",
    "naive_bayes.fit(train)\n",
    "print(f\"Probability for each category: {naive_bayes.category_prob}\")\n",
    "print(f\"Length of self.ngram_count: {len(naive_bayes.ngram_count)}\")\n",
    "print(f\"Shape of the counts for 1st category: {naive_bayes.ngram_count[0].shape}\")\n",
    "print(f\"Number of non-zero terms for 1st category: {(naive_bayes.ngram_count[0] > 0).sum()}\")\n",
    "print(f\"Maximum count of the 1st category: {naive_bayes.ngram_count[0].max()}\")\n",
    "print(f\"Minimum count of the 1st category: {naive_bayes.ngram_count[0].min()}\")\n",
    "print(f\"Sum of ngram count for 1st category: {naive_bayes.ngram_count[0].sum()}\")\n",
    "print(f\"Total count for each category: {naive_bayes.total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132714c-e04c-49b4-8e9c-afebc00c7c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hillary = pd.read_csv(f\"{dataset_directory}/stance_hillary_train.csv\")\n",
    "train_feminist = pd.read_csv(f\"{dataset_directory}/stance_feminist_train.csv\")\n",
    "train_climate = pd.read_csv(f\"{dataset_directory}/stance_climate_train.csv\")\n",
    "train_atheism = pd.read_csv(f\"{dataset_directory}/stance_atheism_train.csv\")\n",
    "train_abortion = pd.read_csv(f\"{dataset_directory}/stance_abortion_train.csv\")\n",
    "\n",
    "dataset_test = [f\"{dataset_directory}/stance_hillary_test.csv\", \n",
    "                 f\"{dataset_directory}/stance_feminist_test.csv\", \n",
    "                 f\"{dataset_directory}/stance_climate_test.csv\", \n",
    "                 f\"{dataset_directory}/stance_atheism_test.csv\", \n",
    "                 f\"{dataset_directory}/stance_abortion_test.csv\"]\n",
    "\n",
    "test_hillary = pd.read_csv(f\"{dataset_directory}/stance_hillary_test.csv\")\n",
    "test_feminist = pd.read_csv(f\"{dataset_directory}/stance_feminist_test.csv\")\n",
    "test_climate = pd.read_csv(f\"{dataset_directory}/stance_climate_test.csv\")\n",
    "test_atheism = pd.read_csv(f\"{dataset_directory}/stance_atheism_test.csv\")\n",
    "test_abortion = pd.read_csv(f\"{dataset_directory}/stance_abortion_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da061e-a4ea-43ba-8b94-f8723765653c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayes()\n",
    "naive_bayes.fit(train_climate)\n",
    "preds = naive_bayes.predict(test_climate['text'])\n",
    "\n",
    "labels = test_climate['label']\n",
    "\n",
    "accuracy, mac_f1, mic_f1 = evaluate(preds, labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Macro f1: {mac_f1}\")\n",
    "print(f\"Micro f1: {mic_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e0182-cd56-4554-94a3-e39c4da2795f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = naive_bayes.predict(test['text'])\n",
    "labels = test['label']\n",
    "print(f\"Prediction: {preds[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b71babf-491f-410b-92ae-9832a020edc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy, mac_f1, mic_f1 = evaluate(preds, labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Macro f1: {mac_f1}\")\n",
    "print(f\"Micro f1: {mic_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8048d-f5b0-411e-bd34-faae7c4de128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, linear_size, lstm_hidden_size, net_dropout, lstm_dropout):\n",
    "\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        self.model_name = 'BiLSTM'\n",
    "        \n",
    "        self.dropout = nn.Dropout(net_dropout)\n",
    "        \n",
    "        self.hidden_size = lstm_hidden_size\n",
    "        self.lstm = nn.LSTM(1024, self.hidden_size, dropout=lstm_dropout, bidirectional=True)\n",
    "        self.linear = nn.Linear(self.hidden_size*2, linear_size)\n",
    "        self.out = nn.Linear(linear_size, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, x_len, epoch, target_word, _):\n",
    "        \n",
    "        x = x.squeeze(1)\n",
    "        \n",
    "        seq_lengths, perm_idx = x_len.sort(0, descending=True)\n",
    "        seq_tensor = x[perm_idx,:,:]\n",
    "        packed_input = pack_padded_sequence(seq_tensor, seq_lengths, batch_first=True)\n",
    "        packed_output, (ht, ct) = self.lstm(packed_input)\n",
    "        _, unperm_idx = perm_idx.sort(0)\n",
    "        h_t = ht[:,unperm_idx,:]\n",
    "        h_t = torch.cat((h_t[0,:,:self.hidden_size], h_t[1,:,:self.hidden_size]), 1)\n",
    "        \n",
    "        linear = self.relu(self.linear(h_t))\n",
    "        linear = self.dropout(linear)\n",
    "        out = self.out(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef90b8-ca49-4f6f-93da-de465ecec806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=256):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataframe.iloc[idx, 0]\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "\n",
    "        inputs = self.tokenizer(text)\n",
    "        print(inputs)\n",
    "\n",
    "        return {\n",
    "            'input': torch.tensor(inputs, dtype=torch.str),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "tokenizer = word_tokenize\n",
    "train_dataset = DataFrameDataset(train, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e2f21-e66f-4bc6-b3fb-2531dddfa8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "lstm_hidden_size = 128\n",
    "linear_size = lstm_hidden_size * 2\n",
    "\n",
    "net_dropout = 0.2\n",
    "lstm_dropout = 0.2\n",
    "\n",
    "model = BiLSTM(linear_size, lstm_hidden_size, net_dropout, lstm_dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772bf8b-7bdc-4eb9-b92e-e5d3106ea645",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_bert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64fe84-65c4-42d6-b7af-191a3d96f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_bert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3342a-3c92-404b-b379-ea3dfbab015d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs = [2e-5, 1e-5, 8e-6]\n",
    "batch_sizes = [32, 16]\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        y = get_stance(train_hillary['Stance'], le)\n",
    "        train_model(train_hillary['Tweet'], y, bs,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a4de7-193d-4090-a74f-f5fd8da458d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs = [2e-5, 1e-5, 8e-6]\n",
    "batch_sizes = [32, 16]\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        y = get_stance(train_feminist['Stance'], le)\n",
    "        train_model(train_feminist['Tweet'], y, bs,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065bf735-1925-47f2-ac47-1f07f96a93a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs = [2e-5, 1e-5, 8e-6]\n",
    "batch_sizes = [32, 16]\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        y = get_stance(train_climate['Stance'], le)\n",
    "        train_model(train_climate['Tweet'], y, bs,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b018cb-4052-4cd2-9890-373243e24184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs = [2e-5, 1e-5, 8e-6]\n",
    "batch_sizes = [32, 16]\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        y = get_stance(train_atheism['Stance'], le)\n",
    "        train_model(train_atheism['Tweet'], y, bs,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92cd75-e4a9-4bf8-a075-0b20198367d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs = [2e-5, 1e-5, 8e-6]\n",
    "batch_sizes = [32, 16]\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        y = get_stance(train_abortion['Stance'], le)\n",
    "        train_model(train_abortion['Tweet'], y, bs,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20334924-5f85-4ac2-8970-e66105dc0ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"trained_models\")\n",
    "y = encode_labels(aa_df['Stance'], le)\n",
    "model, _ = train_whole_model(train_hillary['Tweet'], y, 16, 8e-6,8)\n",
    "model.save('stance_hillary_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b99053-c8aa-44b6-aa11-286fdb6a8d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, _ = train_whole_model(train_feminist['Tweet'], y, 16, 8e-6,8)\n",
    "model.save('stance_feminist_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05896bc6-99f3-4e8d-a37f-315741c734d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, _ = train_whole_model(test_climate['Tweet'], y, 16, 8e-6,8)\n",
    "model.save('stance_climate_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57925ae1-b202-43d7-bb19-5749b4a7a190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, _ = train_whole_model(test_atheism['Tweet'], y, 16, 8e-6,8)\n",
    "model.save('stance_atheism_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7cda3-3b56-4ffb-a8cc-31c9f72f7366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, _ = train_whole_model(train_abortion['Tweet'], y, 16, 8e-6,8)\n",
    "model.save('stance_abortion_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f02d48-1566-424b-8987-7c6500b187dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "rpvgQv1zreND",
    "outputId": "71bf3fc3-eb83-46b5-d6c6-9f534b9a4b54",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_result(get_model(stance_hillary_train.h5), test_hillary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788fd9f1-7eda-4595-959d-6cb42ca41434",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "3waJNg-5dqnX",
    "outputId": "bfbb6598-2aca-4f87-bc43-75f37d71f8bb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_result(get_model(stance_feminist_train.h5):, test_feminist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbb515-ba92-4ba1-b87c-3ba89ca87c2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "aPk1lfPzdqnZ",
    "outputId": "5d0bb695-64ba-4051-d270-139828e40491",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_result(get_model(stance_climate_train.h5):, test_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870fb8ba-3da0-4afc-b1b2-f7d3c3de38f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "ueZmpbDKdqnp",
    "outputId": "a8699a76-2dc2-4c28-cb6b-e36c0f695772",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_result(get_model(stance_atheism_train.h5):, test_atheism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06196cbd-1353-4e4b-aa13-db7ad6550469",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "8SRGnTn4EvGX",
    "outputId": "d7c03bdb-6aa9-452b-c5b4-ed4e95806dcf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_result(get_model(stance_abortion_train.h5):, test_abortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336eb0a-4ac4-4751-9a64-5fee4a719673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
